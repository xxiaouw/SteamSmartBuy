{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"steam_top_games_with_price_logs_and_game_info.csv\")\n",
    "p = pd.read_csv(\"table_price_log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Game Quality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['positive_review_rate'] = df['positive_review']/df['total_review']\n",
    "df['has_metacritic'] = df['metacritic_scores'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "sd_scaler = StandardScaler()\n",
    "\n",
    "df['log_total_review'] = np.log10(df['total_review']) #.replace(0, np.nan)\n",
    "df['sd_total_review'] = sd_scaler.fit_transform(df[['total_review']])\n",
    "df['mm_lg_total_review'] = mm_scaler.fit_transform(df[['log_total_review']])\n",
    "df['mm_sd_total_review'] = mm_scaler.fit_transform(df[['sd_total_review']])\n",
    "df['mm_metacritic_scores_augmented'] = mm_scaler.fit_transform(df[['metacritic_scores_augmented']])\n",
    "df = df.sort_values(\"steam_id\").reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deal Quality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "p['date'] = pd.to_datetime(p['date'], errors='coerce')\n",
    "\n",
    "# most recent price & regular price\n",
    "most_recent_price = p.sort_values('date').groupby('steam_id').last().reset_index()[['steam_id', 'price', 'regular']]\n",
    "most_recent_price.rename(columns={'price': 'current_price', 'regular':'regular_price'}, inplace=True)\n",
    "\n",
    "# history low\n",
    "min_price = p.loc[p.groupby('steam_id')['price'].transform('min') == p['price']]\n",
    "min_price_latest = min_price.sort_values('date').groupby('steam_id').last().reset_index()[['steam_id', 'price', 'date']]\n",
    "min_price_latest.rename(columns={'price': 'lowest_price', 'date': 'lowest_price_date'}, inplace=True)\n",
    "\n",
    "# deal rate\n",
    "rate = p.sort_values('date').groupby('steam_id').last().reset_index()[['steam_id', 'cut_pct']]\n",
    "rate['cut_pct'] = rate['cut_pct'] / 100\n",
    "rate.rename(columns={'cut_pct': 'deal_rate'}, inplace=True)\n",
    "\n",
    "# avg deal rate\n",
    "avg_cut = p[p['cut_pct'] != 0].groupby('steam_id', as_index=False)['cut_pct'].mean()\n",
    "avg_cut['cut_pct'] = avg_cut['cut_pct'] / 100\n",
    "avg_cut.rename(columns={'cut_pct': 'avg_deal_rate'}, inplace=True)\n",
    "\n",
    "# last year deal count\n",
    "one_year_ago = datetime.now(timezone.utc) - timedelta(days=365)\n",
    "p_last_year_deals = p[(p['date'] >= one_year_ago) & (p['cut_pct'] != 0)]\n",
    "deal_count_last_year = p_last_year_deals.groupby('steam_id').size().reset_index(name='deal_count_last_365_days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = (\n",
    "    df\n",
    "    .merge(min_price_latest, on='steam_id',how='left')\n",
    "    .merge(most_recent_price, on='steam_id',how='left')\n",
    "    .merge(rate, on='steam_id',how='left')\n",
    "    .merge(avg_cut, on='steam_id',how='left')\n",
    "    .merge(deal_count_last_year, on='steam_id',how='left')\n",
    ")\n",
    "\n",
    "game['highest_deal_rate'] = 1-game[\"lowest_price\"]/game[\"regular_price\"]\n",
    "game['deal_amount'] = game['regular_price'] - game['current_price']\n",
    "\n",
    "game = game.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating how many days has passed since last deal\n",
    "# Note: if the game is currently on deal, the script search for the 2nd last date for deal\n",
    "# Sort data by steam_id and date descending\n",
    "p_sorted = p.sort_values(['steam_id', 'date'], ascending=[True, False])\n",
    "\n",
    "def get_latest_previous_deal(group):\n",
    "    # Latest row\n",
    "    latest = group.iloc[0]\n",
    "    \n",
    "    # Filter all rows where cut_pct != 0\n",
    "    deals = group[group['cut_pct'] != 0]\n",
    "\n",
    "    if len(deals) == 0:\n",
    "        return pd.Series({'steam_id': latest['steam_id'], 'last_deal_date': pd.NaT})\n",
    "    \n",
    "    if latest['cut_pct'] != 0:\n",
    "        # Return second most recent deal if exists\n",
    "        if len(deals) > 1:\n",
    "            return pd.Series({'steam_id': latest['steam_id'], 'last_deal_date': deals.iloc[1]['date']})\n",
    "        else:\n",
    "            today = datetime.now(timezone.utc)\n",
    "            return pd.Series({'steam_id': latest['steam_id'], 'last_deal_date': today})\n",
    "    else:\n",
    "        return pd.Series({'steam_id': latest['steam_id'], 'last_deal_date': deals.iloc[0]['date']})\n",
    "\n",
    "# Apply per group\n",
    "last_deal_df = p_sorted.groupby('steam_id')[[\"steam_id\",\"date\",\"cut_pct\"]].apply(get_latest_previous_deal).reset_index(drop=True)\n",
    "\n",
    "game = (\n",
    "    game\n",
    "    .merge(last_deal_df, on='steam_id',how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "today = datetime.now(timezone.utc)\n",
    "\n",
    "game['diff_avg_rate'] = game['deal_rate'] - game['avg_deal_rate']\n",
    "game['diff_lowest_rate'] = game['deal_rate'] - game['highest_deal_rate']\n",
    "game['diff_lowest_amount'] = game['current_price'] - game['lowest_price']\n",
    "game['days_since_last_deal'] = (today - game['last_deal_date']).dt.days\n",
    "game['clipped_days_since_last_deal'] = game['days_since_last_deal'].clip(upper=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "sd_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "game['log_deal_amount'] = np.log10(game['deal_amount']+0.1)\n",
    "game['mm_lg_deal_amount'] = mm_scaler.fit_transform(game[['log_deal_amount']])\n",
    "game['mm_sd_deal_amount'] = mm_scaler.fit_transform(sd_scaler.fit_transform(game[['deal_amount']]))\n",
    "game['mm_sd_diff_avg_rate'] = mm_scaler.fit_transform(sd_scaler.fit_transform(game[['diff_avg_rate']]))\n",
    "game['mm_sd_diff_lowest_rate'] = mm_scaler.fit_transform(sd_scaler.fit_transform(game[['diff_lowest_rate']]))\n",
    "game['mm_sd_diff_lowest_amount'] = 1-mm_scaler.fit_transform(sd_scaler.fit_transform(game[['diff_lowest_amount']]))\n",
    "# game['mm_sd_days_since_last_deal'] = mm_scaler.fit_transform(sd_scaler.fit_transform(game[['days_since_last_deal']]))\n",
    "game['mm_sd_clipped_days_since_last_deal'] = mm_scaler.fit_transform(sd_scaler.fit_transform(game[['clipped_days_since_last_deal']]))\n",
    "game['mm_sd_deal_count_last_365_days'] = 1-mm_scaler.fit_transform(sd_scaler.fit_transform(game[['deal_count_last_365_days']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game['game_quality_lg'] = (game['positive_review_rate'] * 0.15 + \\\n",
    "                           game['mm_lg_total_review'] * 0.1 + \\\n",
    "                           game['mm_metacritic_scores_augmented'] * 0.1)/0.35\n",
    "\n",
    "game['game_quality_sd'] = (game['positive_review_rate'] * 0.15 + \\\n",
    "                           game['mm_sd_total_review'] * 0.1 + \\\n",
    "                           game['mm_metacritic_scores_augmented'] * 0.1)/0.35\n",
    "\n",
    "game['deal_quality_sd'] = (game['deal_rate'] * 0.175 + \\\n",
    "                        game['mm_sd_deal_amount'] * 0.175 + \\\n",
    "                        game['mm_sd_diff_avg_rate'] * 0.1 + \\\n",
    "                        game['mm_sd_diff_lowest_rate'] * 0.1 + \\\n",
    "                        game['mm_sd_diff_lowest_amount'] * 0.05 + \\\n",
    "                        game['mm_sd_clipped_days_since_last_deal'] * 0.03 + \\\n",
    "                        game['mm_sd_deal_count_last_365_days'] * 0.02)/0.65\n",
    "\n",
    "game['deal_quality_lg'] = (game['deal_rate'] * 0.175 + \\\n",
    "                        game['mm_lg_deal_amount'] * 0.175 + \\\n",
    "                        game['mm_sd_diff_avg_rate'] * 0.1 + \\\n",
    "                        game['mm_sd_diff_lowest_rate'] * 0.1 + \\\n",
    "                        game['mm_sd_diff_lowest_amount'] * 0.05 + \\\n",
    "                        game['mm_sd_clipped_days_since_last_deal'] * 0.03 + \\\n",
    "                        game['mm_sd_deal_count_last_365_days'] * 0.02)/0.65\n",
    "\n",
    "game[\"score_lg\"] = game[\"game_quality_lg\"]*0.35+game[\"deal_quality_lg\"]*0.65\n",
    "game[\"score_sd\"] = game[\"game_quality_sd\"]*0.35+game[\"deal_quality_sd\"]*0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deal Quality Tunning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Game Score Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = game[['steam_id', 'game', 'game_quality_lg', 'game_quality_sd', 'deal_quality_sd', 'deal_quality_lg', 'score_lg', 'score_sd',\\\n",
    "              'current_price', 'regular_price', 'lowest_price', 'lowest_price_date', 'review_desc',\\\n",
    "              'deal_rate', 'avg_deal_rate', 'deal_amount', 'deal_count_last_365_days', 'positive_review_rate']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['on_deal'] = (score['deal_rate'] != 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score.drop(columns=['deal_quality_sd', 'game_quality_sd', 'score_sd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['game_quality_lg'] = score['game_quality_lg']*100\n",
    "score['deal_quality_lg'] = score['deal_quality_lg']*100\n",
    "score['score_lg'] = score['score_lg']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.to_csv(\"table_score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Last Deal Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last deal date\n",
    "# DIFFERENT FROM SCORE CAL\n",
    "\n",
    "score = pd.read_csv(\"table_score.csv\")\n",
    "\n",
    "# Calculating how many days has passed since last deal\n",
    "p = pd.read_csv(\"table_price_log.csv\")\n",
    "p['date'] = pd.to_datetime(p['date'])\n",
    "p_sorted = p.sort_values(['steam_id', 'date'], ascending=[True, False])\n",
    "\n",
    "def get_latest_previous_deal_UESR(group):\n",
    "    # Latest row\n",
    "    latest = group.iloc[0]\n",
    "    \n",
    "    # Filter all rows where cut_pct != 0\n",
    "    deals = group[group['cut_pct'] != 0]\n",
    "\n",
    "    if len(deals) == 0:\n",
    "        return pd.Series({'steam_id': latest['steam_id'], 'last_deal_date': pd.NaT})\n",
    "    \n",
    "    return pd.Series({'steam_id': latest['steam_id'], 'last_deal_date': deals.iloc[0]['date']})\n",
    "\n",
    "# Apply per group\n",
    "last_deal_df = p_sorted.groupby('steam_id')[[\"steam_id\",\"date\",\"cut_pct\"]].apply(get_latest_previous_deal_UESR).reset_index(drop=True)\n",
    "\n",
    "score = (\n",
    "    score\n",
    "    .merge(last_deal_df, on='steam_id',how='left')\n",
    ")\n",
    "\n",
    "score.to_csv(\"table_score.csv\", index=False)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Avg Days Between Deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess\n",
    "df = pd.read_csv('table_price_log.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date_only'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "# Filter only deal dates (cut_pct ≠ 0)\n",
    "deals_df = df[df['cut_pct'] != 0].copy()\n",
    "\n",
    "# Sort by steam_id and date\n",
    "deals_df.sort_values(['steam_id', 'date'], inplace=True)\n",
    "deals_df = deals_df.drop_duplicates(subset=['steam_id', 'date_only'], keep='first')\n",
    "deals_df.drop(columns=['date_only'], inplace=True)\n",
    "\n",
    "# Calculate time difference between consecutive deals\n",
    "deals_df['days_between_deal'] = deals_df.groupby('steam_id')['date'].diff().dt.days\n",
    "\n",
    "# Now calculate average days between deals per steam_id\n",
    "avg_days_between_deals = (\n",
    "    deals_df.groupby('steam_id')['days_between_deal']\n",
    "    .mean()\n",
    "    .reset_index(name='avg_days_between_deals')\n",
    ")\n",
    "\n",
    "score = pd.read_csv(\"table_score.csv\")\n",
    "\n",
    "score = (\n",
    "    score\n",
    "    .merge(avg_days_between_deals, on='steam_id',how='left')\n",
    ")\n",
    "\n",
    "score.to_csv(\"table_score.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
